## Practical Machine Learning Course Project


### Summary
#### Two modeling methods were utilized for this project, Classification Tree and Random Forest. For both methods, 5-fold cross validation is used.

### Load Packages

```{r}
library(caret)
library(randomForest)
library(rattle)
library(rpart.plot)
library(AppliedPredictiveModeling)
```

### Import Data
It is assumed that data files are located in working directory

```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA",""), header=TRUE)
colnames_train <- colnames(training)
testing <- read.csv("pml-testing.csv", na.strings=c("NA",""), header=TRUE)
colnames_test <- colnames(testing)
```

### Remove columns that aren't needed. NA data is cleaned, as well.

```{r}
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]

training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]
```

### Training data is separated into training and test sets

```{r}
set.seed(1111)
ids_small <- createDataPartition(y=training$classe, p=0.25, list=FALSE)
small <- training[ids_small,]
remainder <- training[-ids_small,]

set.seed(1111)
Train <- createDataPartition(y=small$classe, p=0.6, list=FALSE)
small_training <- small[Train,]
small_testing <- small[-Train,]
```

## Classification Tree

```{r}
set.seed(1111)
control <- trainControl(method = "cv", number = 5)
fit_rpart <- train(classe ~ ., data = small_training, method = "rpart", trControl = control)
print(fit_rpart, digits=3)
```

```{r}
fancyRpartPlot(fit_rpart$finalModel)
```

### Classification Tree Prediction

```{r}
predict_rpart <- predict(fit_rpart, newdata=small_testing)
print(confusionMatrix(predict_rpart, small_testing$classe), digits=4)
```

CT Accuracy 0.4768

## Random Forest

```{r}
set.seed(1111)
fit_rf <- train(classe ~ ., data = small_training, method = "rf", trControl = control)
print(fit_rf, digits = 4)
```

### Random Forest Prediction

```{r}
predict_rf <- predict(fit_rf, newdata=small_testing)
print(confusionMatrix(predict_rf, small_testing$classe), digits=4)
```

RF Accuracy 0.9704

#### After a head to head comparison, Random Forest method (0.9704) proved to be more accurate than Classification Tree method (0.4768).

### Test set Prediction

```{r}
prediction <- predict(fit_rf, newdata=testing)
prediction
```
